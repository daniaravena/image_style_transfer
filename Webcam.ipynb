{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCameraFrame:\n",
    "    def __init__(self,window_name='Webcam Image Style Transfer'):\n",
    "        self.width = 480\n",
    "        self.height = 320\n",
    "        self.result_frame = np.zeros((320, 480, 3), np.uint8)\n",
    "        self.window_name = window_name\n",
    "        self.init_window()\n",
    "        self.cap = None\n",
    "\n",
    "    def init_window(self):\n",
    "        cv.namedWindow(self.window_name, cv.WINDOW_NORMAL)\n",
    "        cv.setWindowTitle(self.window_name, self.window_name)\n",
    "        cv.resizeWindow(self.window_name, self.width, self.height)\n",
    "        cv.moveWindow(self.window_name, 0, 0)\n",
    "        cv.imshow(self.window_name,self.result_frame)\n",
    "\n",
    "    def open_cam_usb(self, dev=0):\n",
    "        # We want to set width and height here, otherwise we could just do:\n",
    "        self.cap = cv.VideoCapture(dev)\n",
    "        return\n",
    "        # gst_str = ('v4l2src device=/dev/video{} ! '\n",
    "        #            'video/x-raw, width=(int){}, height=(int){}, '\n",
    "        #            'format=(string)RGB ! '\n",
    "        #            'videoconvert ! appsink').format(dev, self.width, self.height)\n",
    "        # self.cap = cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)\n",
    "\n",
    "    def open_cam_onboard(self):\n",
    "        # ONLY ON JETSON TX2\n",
    "\n",
    "        # On versions of L4T prior to 28.1, add 'flip-method=2' into gst_str\n",
    "        gst_str = ('nvcamerasrc ! '\n",
    "                   'video/x-raw(memory:NVMM), '\n",
    "                   'width=(int)2592, height=(int)1458, '\n",
    "                   'format=(string)I420, framerate=(fraction)30/1 ! '\n",
    "                   'nvvidconv ! '\n",
    "                   'video/x-raw, width=(int){}, height=(int){}, '\n",
    "                   'format=(string)BGRx ! '\n",
    "                   'videoconvert ! appsink').format(self.width, self.height)\n",
    "        self.cap = cv.VideoCapture(gst_str, cv.CAP_GSTREAMER)\n",
    "\n",
    "    def get_frame(self):\n",
    "\n",
    "        retval, frame = self.cap.read()  # grab the next image frame from camera\n",
    "\n",
    "        return exit, frame\n",
    "\n",
    "#     def show_in_window(self, image_origin, image, detection_result, help_text=None):\n",
    "\n",
    "#         result_frame = np.zeros((320, 480, 3), np.uint8)\n",
    "\n",
    "#         image_y, image_x,_ = image_origin.shape\n",
    "\n",
    "#         image_max_x = 480 // 2\n",
    "#         image_max_y = 320\n",
    "\n",
    "#         image_ratio = image_y / image_x\n",
    "#         new_image_x = image_x\n",
    "#         new_image_y = image_y\n",
    "\n",
    "#         # if image is square or taller than width,\n",
    "#         # resize the image to max height and align width\n",
    "#         if image_y >= image_x:\n",
    "#             # if image_y > image_max_y:\n",
    "#             new_image_y = image_max_y\n",
    "#             new_image_x = int(image_max_y / image_ratio)\n",
    "\n",
    "#         # else: set width to max width and align height\n",
    "#         else:\n",
    "#             new_image_x = image_max_x\n",
    "#             new_image_y = int(image_ratio * image_max_x)\n",
    "\n",
    "#         # adapt the new image sizes to the images\n",
    "#         image_origin = cv.resize(image_origin, (new_image_x, new_image_y))\n",
    "#         image = cv.resize(image, (new_image_x, new_image_y))\n",
    "\n",
    "#         result_frame[0:new_image_y, 0:new_image_x] = image_origin\n",
    "#         result_frame[0:new_image_y, new_image_x:2 * new_image_x] = image\n",
    "\n",
    "#         if detection_result is not None:\n",
    "#             detection_result = cv.cvtColor(detection_result, cv.COLOR_GRAY2RGB)\n",
    "#             result_frame[800:1000, 0:1800] = detection_result\n",
    "#         if help_text:\n",
    "#             cv.putText(result_frame, help_text, (20, 1010), cv.FONT_HERSHEY_PLAIN, 1.0, (32, 32, 32), 4, cv.LINE_AA)\n",
    "#             cv.putText(result_frame, help_text, (20, 1010), cv.FONT_HERSHEY_PLAIN, 1.0, (240, 240, 240), 1, cv.LINE_AA)\n",
    "\n",
    "#         cv.imshow(self.window_name, result_frame)\n",
    "\n",
    "    def close(self):\n",
    "        self.cap.release()\n",
    "        self.cap = None\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StylizeWebcam:\n",
    "\n",
    "    def __init__(self, window_name='Webcam Image Style Transfer'):\n",
    "        self.cam = VideoCameraFrame(window_name=window_name)\n",
    "\n",
    "    def detect_faces(self, frame):\n",
    "\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # No faces found\n",
    "        if isinstance(faces,tuple):\n",
    "            return\n",
    "\n",
    "        # get the face from the image frame and resize it for prediction\n",
    "        image_faces = []\n",
    "        for idx, (x,y,w,h) in enumerate(faces):\n",
    "            face = gray[y:y+h,x:x+w]\n",
    "            face = cv.resize(face, (SIZE_FACE, SIZE_FACE), interpolation=cv.INTER_CUBIC) / 255.\n",
    "            image_faces.append(face)\n",
    "\n",
    "        faces_for_prediction = np.array(image_faces)\n",
    "        prediction = self.network.predict(faces_for_prediction)\n",
    "        prediction = np.round(prediction,3)\n",
    "        prediction_class = np.argmax(prediction,1)\n",
    "\n",
    "        # adapted for screen\n",
    "        detection_result = np.ones((200, 1800), np.uint8)\n",
    "\n",
    "        # swap each face with its predicted class emoji.\n",
    "        # create an additional detection result,\n",
    "        # which shows the cut out face and the model prediction as bar chart.\n",
    "        for idx, (x, y, w, h) in enumerate(faces):\n",
    "            emoji = self.emoji_images[prediction_class[idx]]\n",
    "            emoji = cv.resize(emoji, (w, h))\n",
    "\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            img2gray = cv.cvtColor(emoji, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY)\n",
    "\n",
    "            mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "            img1_bg = cv.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "            img2_fg = cv.bitwise_and(emoji, emoji, mask=mask)\n",
    "\n",
    "            dst = cv.add(img1_bg, img2_fg)\n",
    "            frame[y:y+h, x:x+w] = dst\n",
    "\n",
    "            # create for nine faces a detection result\n",
    "            if idx < 9:\n",
    "                image_faces[idx] = cv.resize(image_faces[idx], (200, 200)) * 255\n",
    "                for index, emotion in enumerate(EMOTIONS):\n",
    "\n",
    "                    cv.putText(image_faces[idx],\n",
    "                               emotion,\n",
    "                               (10, index * 20 + 20),\n",
    "                               cv.FONT_HERSHEY_PLAIN,\n",
    "                               0.8,\n",
    "                               (0, 255, 0),\n",
    "                               1)\n",
    "                    cv.rectangle(image_faces[idx],\n",
    "                                 (100, index * 20 + 10),\n",
    "                                 (100 + int(prediction[idx][index] * 100),\n",
    "                                 (index + 1) * 20 + 4),\n",
    "                                 (255, 0, 0),\n",
    "                                 -1)\n",
    "\n",
    "                x1 = idx * 200\n",
    "                y1 = 0\n",
    "\n",
    "                detection_result[y1:y1+200, x1:x1+200] = image_faces[idx]\n",
    "\n",
    "        return detection_result\n",
    "    \n",
    "    def styleize(self,frame):\n",
    "        \n",
    "\n",
    "    def run_on_camera(self, cam_dev=0):\n",
    "        HELP_TEXT = '\"Esc\" to Quit'\n",
    "        fps = ''\n",
    "        h_text = HELP_TEXT\n",
    "        show_help = True\n",
    "\n",
    "#         self.cam.open_cam_usb(cam_dev)\n",
    "        self.cam.open_cam_onboard()\n",
    "        do_exit = False\n",
    "        while not do_exit:\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            retval, frame_origin = self.cam.get_frame()\n",
    "            frame = frame_origin.copy()\n",
    "#             detection_result = self.detect_faces(frame)\n",
    "            end = time.time()\n",
    "\n",
    "            if end-start != 0:\n",
    "                fps = str(round(1 / (end - start), 2))\n",
    "\n",
    "            key = cv.waitKey(10)\n",
    "            if show_help:\n",
    "                h_text = HELP_TEXT + '; FPS: '+fps\n",
    "            if key == 27:  # ESC key: quit program\n",
    "                do_exit = True\n",
    "\n",
    "#             self.cam.show_in_window(frame_origin, frame, detection_result,help_text=h_text)\n",
    "\n",
    "        self.cam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "webcam = StylizeWebcam()\n",
    "webcam.run_on_camera(cam_dev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
